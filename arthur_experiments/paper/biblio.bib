@article {Allasson.statfram,
author = {Allassonnière, S. and Amit, Y. and Trouvé, A.},
title = {Towards a coherent statistical framework for dense deformable template estimation},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {69},
number = {1},
publisher = {Blackwell Publishing Ltd},
issn = {1467-9868},
url = {http://dx.doi.org/10.1111/j.1467-9868.2007.00574.x},
doi = {10.1111/j.1467-9868.2007.00574.x},
pages = {3--29},
keywords = {Bayesian estimation, Deformable templates, Expectation–maximization algorithm, Mixture models, Object recognition},
year = {2007},
}

@inproceedings{chen.infogan,
  abstract     = {This paper describes InfoGAN, an information-theoretic extension to the Gener-ative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound of the mutual information objective that can be optimized efficiently. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, pres-ence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods.},
  author       = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  booktitle    = {Advances in Neural Information Processing Systems},
  language     = {eng},
  location     = {Barcelona, Spain},
  title        = {InfoGAN: interpretable representation learning by information maximizing Generative Adversarial Nets},
  url          = {https://arxiv.org/abs/1606.03657},
  year         = {2016},
}

@InProceedings{cohen.groupequi,
  title =    {Group Equivariant Convolutional Networks},
  author =   {Taco Cohen and Max Welling},
  booktitle =    {Proceedings of The 33rd International Conference on Machine Learning},
  pages =    {2990--2999},
  year =     {2016},
  editor =   {Maria Florina Balcan and Kilian Q. Weinberger},
  volume =   {48},
  series =   {Proceedings of Machine Learning Research},
  address =      {New York, New York, USA},
  month =    {20--22 Jun},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v48/cohenc16.pdf},
  url =      {http://proceedings.mlr.press/v48/cohenc16.html},
  abstract =     {We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.}
}

@article{Geman:1984:SRG:2286442.2286617,
 author = {Geman, Stuart and Geman, Donald},
 title = {Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images},
 journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
 issue_date = {November 1984},
 volume = {6},
 number = {6},
 month = nov,
 year = {1984},
 issn = {0162-8828},
 pages = {721--741},
 numpages = {21},
 url = {http://dx.doi.org/10.1109/TPAMI.1984.4767596},
 doi = {10.1109/TPAMI.1984.4767596},
 acmid = {2286617},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Annealing, Gibbs distribution, MAP estimate, Markov random field, image restoration, line process, relaxation, scene modeling, spatial degradation},
} 

@ARTICLE{Goodfellow.gan,
   author = {{Goodfellow}, I.~J. and {Pouget-Abadie}, J. and {Mirza}, M. and 
    {Xu}, B. and {Warde-Farley}, D. and {Ozair}, S. and {Courville}, A. and 
    {Bengio}, Y.},
    title = "{Generative Adversarial Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1406.2661},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2014,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1406.2661G},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@incollection{Jaderberg.stn,
title = {Spatial Transformer Networks},
author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2017--2025},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf}
}


@article{Jordan:VarMethods,
 author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
 title = {An Introduction to Variational Methods for Graphical Models},
 journal = {Mach. Learn.},
 issue_date = {Nov.1.1999},
 volume = {37},
 number = {2},
 month = nov,
 year = {1999},
 issn = {0885-6125},
 pages = {183--233},
 numpages = {51},
 url = {http://dx.doi.org/10.1023/A:1007665907178},
 doi = {10.1023/A:1007665907178},
 acmid = {339252},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Bayesian networks, Boltzmann machines, approximate inference, belief networks, graphical models, hidden Markov models, mean field methods, neural networks, probabilistic inference, variational methods},
} 

@ARTICLE{Kingma.aevb,
   author = {{Kingma}, D.~P and {Welling}, M.},
    title = "{Auto-Encoding Variational Bayes}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1312.6114},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2013,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6114K},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{lecun-gradientbased-learning-applied-1998,
  added-at = {2017-05-15T10:09:50.000+0200},
  author = {LeCun, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
  biburl = {https://www.bibsonomy.org/bibtex/29aa18bc67d862bdb83b6081e5506f050/albinzehe},
  booktitle = {Proceedings of the IEEE},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
  file = {:neural_nets/lecun-98.pdf:PDF;:lecun-98.pdf:PDF},
  groups = {public},
  interhash = {7a82cccacd23cf06b25ff5325a6c86c7},
  intrahash = {9aa18bc67d862bdb83b6081e5506f050},
  keywords = {cnn neuralnets},
  number = 11,
  pages = {2278--2324},
  timestamp = {2017-05-15T10:09:50.000+0200},
  title = {Gradient-Based Learning Applied to Document Recognition},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
  username = {mhwombat},
  volume = 86,
  year = 1998
}

@article{mnistlecun,
    author = {Lecun, Yann and Cortes, Corinna},
    citeulike-article-id = {599493},
    citeulike-linkout-0 = {http://yann.lecun.com/exdb/mnist/},
    keywords = {ai, mnist, recognition},
    posted-at = {2009-03-20 17:02:13},
    priority = {2},
    title = {{The MNIST database of handwritten digits}},
    url = {http://yann.lecun.com/exdb/mnist/}
}

@article{Mescheder.advvae,
  author    = {Lars M. Mescheder and
               Sebastian Nowozin and
               Andreas Geiger},
  title     = {Adversarial Variational Bayes: Unifying Variational Autoencoders and
               Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1701.04722},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.04722},
  timestamp = {Wed, 07 Jun 2017 14:40:36 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MeschederNG17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Siyu:vae,
 author = {Song, Siyu},
 title = {A Variational Auto-Encoder Learning Spatial Transformation Equivariance},
 journal = {Unpublished},
 issue_date = {Feb.9.2017},
 month = feb,
 year = {2017},
} 

@ARTICLE{Zhao.infoVAE,
   author = {{Zhao}, S. and {Song}, J. and {Ermon}, S.},
    title = "{InfoVAE: Information Maximizing Variational Autoencoders}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1706.02262},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
     year = 2017,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170602262Z},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{JangCatReparam,
   author = {{Jang}, E. and {Gu}, S. and {Poole}, B.},
    title = "{Categorical Reparameterization with Gumbel-Softmax}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1611.01144},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2016,
    month = nov,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv161101144J},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{cifar10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

@article{svhn,
title= {Reading Digits in Natural Images with Unsupervised Feature Learning},
journal= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning},
author= {Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng},
year= {2011}
}
